{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HalSMOMeUjeZ"
   },
   "source": [
    "# **Image Classification: US License Plates**\n",
    "## **Background information:**\n",
    "This project consists of a very high-quality dataset, US license plate images from 50 states i.e., total 50 classes for classification. Based on the information provided, all images are originals, no augmented images are present in the dataset. All images are of size 128 pixels X 224 pixels X 3 channels in jpg format. All images have been cropped so the license plate occupies at least 90% of the pixels in any image. This ensures that even simple models will achieve high training, validation and test accuracy. Also included is a csv file that can be used to create train, validation and test sets if desired.\n",
    "\n",
    "## **Dataset source:**\n",
    "https://www.kaggle.com/datasets/gpiosenka/us-license-plates-image-classification\n",
    "\n",
    "## **Criteria for success:**\n",
    "Delivering a model with > 90% accuracy to classify a license plate image into one of different available 50 classes.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBRWkwP57ZNy"
   },
   "source": [
    "# **Modeling Approach I. Non-Neural Network Classifier**\n",
    "\n",
    "This section would examine the performance of following two non-neural network classifiers\n",
    "\n",
    "1.   Random Forest Classfier\n",
    "2.   K-Nearest Neighbors (KNN) Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzxtUpShmczK"
   },
   "source": [
    "## **Model A: Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-vDO8y8mwNc",
    "outputId": "e5c9650f-52a2-4f06-abe0-f582e8b8e7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.19 %\n"
     ]
    }
   ],
   "source": [
    "# Import relevant python libraries\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for state_folder in os.listdir(data_dir):\n",
    "        state_path = os.path.join(data_dir, state_folder)\n",
    "        if os.path.isdir(state_path):\n",
    "            for filename in os.listdir(state_path):\n",
    "                img_path = os.path.join(state_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                images.append(img.flatten())  # Flatten the image array\n",
    "                labels.append(state_folder)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_dir = \"drive/MyDrive/DSC Capstone 3/plates/train\"\n",
    "images, labels = load_and_preprocess_images(data_dir)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_encoded = label_binarizer.fit_transform(y_train)\n",
    "y_test_encoded = label_binarizer.transform(y_test)\n",
    "\n",
    "# Create and train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtyHepvI17jh"
   },
   "source": [
    "## **Model B: K-Nearest Neighbors (KNN) Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU541gVH2M7k",
    "outputId": "cad065ad-34f7-4ac8-c613-8a7de45b27ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.64 %\n"
     ]
    }
   ],
   "source": [
    "# Create and train the KNN Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}\", \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeeVnqS94RCS"
   },
   "source": [
    "# **Modeling Approach II. Neural Networks (Deep Learning) Classifiers**\n",
    "\n",
    "This section would examine the performance of following three neural network *aka* deep learning classifiers\n",
    "\n",
    "1.   Multilevel Perceptron (MLP) Classfier\n",
    "2.   Convolutional Neural Network (CNN) Classifier\n",
    "3.   Transfer Learning (ResNet Model) Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PexeI0Hdk3c1"
   },
   "source": [
    "## **Model A: Multilevel Perceptron (MLP) Classfier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOKNqVdC9WEi",
    "outputId": "9a1e6c29-c0fb-4960-9f8d-cf37b6dd889f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 4.0034 - accuracy: 0.0222\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9141 - accuracy: 0.0248\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.9117 - accuracy: 0.0248\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.9115 - accuracy: 0.0250\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9113 - accuracy: 0.0250\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9111 - accuracy: 0.0250\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9110 - accuracy: 0.0250\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9147 - accuracy: 0.0251\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9107 - accuracy: 0.0250\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.9106 - accuracy: 0.0250\n",
      "46/46 - 0s - loss: 3.9134 - accuracy: 0.0190 - 328ms/epoch - 7ms/step\n",
      "\n",
      "Test Accuracy: 1.90 %\n"
     ]
    }
   ],
   "source": [
    "# Convert to TensorFlow tensors and normalize\n",
    "X_train_tensor = tf.convert_to_tensor(X_train / 255.0, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train_encoded, dtype=tf.float32)\n",
    "\n",
    "# Build the MLP model using TensorFlow and Keras\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(label_binarizer.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi_A9e0Pabc3"
   },
   "source": [
    "### **MLP Model: Increasing number of hidden layers in the model (Deep neural network)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQRjhyJ8am9f",
    "outputId": "babe2a1e-62e9-4b2f-d773-2664dca3006f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.9148 - accuracy: 0.0229\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.8897 - accuracy: 0.0297\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.8559 - accuracy: 0.0403\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.8156 - accuracy: 0.0521\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.7591 - accuracy: 0.0749\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.6829 - accuracy: 0.0929\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.6009 - accuracy: 0.1104\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.5103 - accuracy: 0.1398\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.4159 - accuracy: 0.1566\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.3145 - accuracy: 0.1816\n",
      "46/46 - 0s - loss: 3.5657 - accuracy: 0.1250 - 390ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 12.50 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (5 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01HX-i_IbT_y",
    "outputId": "c21e17d8-a677-46fa-a646-a97db56934d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 3s 10ms/step - loss: 3.9155 - accuracy: 0.0224\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8902 - accuracy: 0.0263\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 2s 11ms/step - loss: 3.8638 - accuracy: 0.0362\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8217 - accuracy: 0.0476\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.7708 - accuracy: 0.0667\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.7075 - accuracy: 0.0851\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.6256 - accuracy: 0.1072\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.5455 - accuracy: 0.1277\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.4354 - accuracy: 0.1501\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.3414 - accuracy: 0.1732\n",
      "46/46 - 0s - loss: 3.5684 - accuracy: 0.1379 - 368ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 13.79 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (4 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oq3utchqpdXE",
    "outputId": "9913a176-23f5-4fcf-9673-c7e03b768094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.9263 - accuracy: 0.0245\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.8933 - accuracy: 0.0290\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.8753 - accuracy: 0.0358\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.8572 - accuracy: 0.0348\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.8374 - accuracy: 0.0370\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.8168 - accuracy: 0.0382\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.7967 - accuracy: 0.0399\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 3.7683 - accuracy: 0.0479\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.7449 - accuracy: 0.0566\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 3.7098 - accuracy: 0.0673\n",
      "46/46 - 0s - loss: 3.8083 - accuracy: 0.0550 - 370ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 5.50 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (3 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7q6OvNMp5zM",
    "outputId": "0bacf538-051f-4bbf-8016-7530997227bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 2s 7ms/step - loss: 3.9650 - accuracy: 0.0214\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9133 - accuracy: 0.0255\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9116 - accuracy: 0.0251\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9113 - accuracy: 0.0251\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9122 - accuracy: 0.0239\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9111 - accuracy: 0.0248\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9109 - accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9111 - accuracy: 0.0251\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9109 - accuracy: 0.0250\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 3.9103 - accuracy: 0.0250\n",
      "46/46 - 0s - loss: 3.9133 - accuracy: 0.0190 - 364ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 1.90 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (2 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIt-NkICqbfX"
   },
   "source": [
    "### **MLP Model: Increasing epochs**\n",
    "\n",
    "This section studies the model perfomance with increasing number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9dA8aY5qYHr",
    "outputId": "9b0a3a8e-9e94-4bb0-fab8-8e56de1071e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "184/184 [==============================] - 3s 10ms/step - loss: 3.9196 - accuracy: 0.0217\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.9008 - accuracy: 0.0228\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8715 - accuracy: 0.0331\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8385 - accuracy: 0.0494\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.7921 - accuracy: 0.0623\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.7296 - accuracy: 0.0730\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.6587 - accuracy: 0.0953\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.5877 - accuracy: 0.1170\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.4829 - accuracy: 0.1413\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.3959 - accuracy: 0.1647\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.2933 - accuracy: 0.1831\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.1759 - accuracy: 0.2075\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.0938 - accuracy: 0.2264\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.0132 - accuracy: 0.2374\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.8971 - accuracy: 0.2689\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.8080 - accuracy: 0.2921\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.7532 - accuracy: 0.3060\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.6802 - accuracy: 0.3268\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.6012 - accuracy: 0.3465\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.5125 - accuracy: 0.3674\n",
      "46/46 - 0s - loss: 3.0972 - accuracy: 0.2745 - 370ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 27.45 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (4 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=20) #2x epochs\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyTM3faWq4i4",
    "outputId": "f9476049-7576-47dd-b58a-7c832c74230c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "184/184 [==============================] - 3s 10ms/step - loss: 3.9211 - accuracy: 0.0197\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8986 - accuracy: 0.0279\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8767 - accuracy: 0.0369\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.8413 - accuracy: 0.0496\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.7913 - accuracy: 0.0596\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 2s 11ms/step - loss: 3.7271 - accuracy: 0.0764\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.6565 - accuracy: 0.0875\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.5831 - accuracy: 0.1028\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.4999 - accuracy: 0.1194\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.4172 - accuracy: 0.1422\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.3406 - accuracy: 0.1676\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.2423 - accuracy: 0.1856\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.1787 - accuracy: 0.2050\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.1021 - accuracy: 0.2303\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 3.0185 - accuracy: 0.2456\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.9215 - accuracy: 0.2663\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.8739 - accuracy: 0.2758\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.7889 - accuracy: 0.2967\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.6880 - accuracy: 0.3173\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.6417 - accuracy: 0.3271\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.5326 - accuracy: 0.3497\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.5004 - accuracy: 0.3592\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.4423 - accuracy: 0.3758\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.3517 - accuracy: 0.3954\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.2993 - accuracy: 0.4093\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.2024 - accuracy: 0.4341\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.1599 - accuracy: 0.4392\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.0620 - accuracy: 0.4711\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 2.0307 - accuracy: 0.4776\n",
      "Epoch 30/30\n",
      "184/184 [==============================] - 2s 10ms/step - loss: 1.9688 - accuracy: 0.4951\n",
      "46/46 - 0s - loss: 3.5330 - accuracy: 0.2330 - 383ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 23.30 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (4 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=30) # 3x epochs\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnsyrWtjrRef"
   },
   "source": [
    "### **MLP Model: Increasing number of neurons in each hidden layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzrPy16yrY-3",
    "outputId": "e1b151e9-112f-4db0-8b40-780b7133a442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.9196 - accuracy: 0.0226\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.8701 - accuracy: 0.0409\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.7896 - accuracy: 0.0594\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.6823 - accuracy: 0.0885\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.5570 - accuracy: 0.1213\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.4128 - accuracy: 0.1602\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.2714 - accuracy: 0.1909\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.1262 - accuracy: 0.2244\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 3.0194 - accuracy: 0.2556\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.8917 - accuracy: 0.2824\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.7600 - accuracy: 0.3111\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.6582 - accuracy: 0.3351\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.5397 - accuracy: 0.3628\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.4443 - accuracy: 0.3794\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.3563 - accuracy: 0.4037\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.2522 - accuracy: 0.4268\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.1630 - accuracy: 0.4502\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 2.0799 - accuracy: 0.4677\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 1.9840 - accuracy: 0.4915\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 1.8831 - accuracy: 0.5149\n",
      "46/46 - 0s - loss: 3.2651 - accuracy: 0.2867 - 386ms/epoch - 8ms/step\n",
      "\n",
      "Test Accuracy: 28.67 %\n"
     ]
    }
   ],
   "source": [
    "# Build the MLP model using TensorFlow and Keras (4 hidden layers)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.Dense(512, activation='relu'), #2x number of neurons\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test / 255.0, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwYpfkbYMnUf"
   },
   "source": [
    "**Key takeaways:**\n",
    "\n",
    "1.   MLP classifier with 4 hidden layers improved test data accuracy by more than an order of magnitude, i.e., from a test data accuracy of 1.9% -> 13.8%\n",
    "2.   MLP classifier with 2x epochs further improve the accuracy of the model by 2x, i.e. from a test data accuracy of 13.8 -> 27.8%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ARLQdhlBwpF"
   },
   "source": [
    "## **Model B: Convolutional Neural Network (CNN) Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tnmr3UljB_Ir",
    "outputId": "f3abad8f-b009-4671-fe28-31279597c693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 6s 28ms/step - loss: 3.9141 - accuracy: 0.0229\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 3.8892 - accuracy: 0.0282\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 3.7909 - accuracy: 0.0679\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 3.4982 - accuracy: 0.1680\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 2.9286 - accuracy: 0.3127\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 2.2565 - accuracy: 0.4621\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 1.6220 - accuracy: 0.6058\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 1.0142 - accuracy: 0.7537\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 0.5243 - accuracy: 0.8792\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 0.3173 - accuracy: 0.9389\n",
      "46/46 - 1s - loss: 2.3430 - accuracy: 0.5374 - 507ms/epoch - 11ms/step\n",
      "\n",
      "Test Accuracy: 53.74 %\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model using TensorFlow and Keras\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(label_binarizer.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_encoded))\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JVoyv316Nmp"
   },
   "source": [
    "### **CNN Model: Implementing batch normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqcJMKXm4yX8",
    "outputId": "9498efea-d12b-4141-8fd6-7b779fa7015c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 11s 39ms/step - loss: 2.6814 - accuracy: 0.4110\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 1.1841 - accuracy: 0.8485\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 0.4898 - accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 0.2078 - accuracy: 0.9985\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 0.1150 - accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.0793 - accuracy: 0.9998\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.0610 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.0495 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.0417 - accuracy: 0.9998\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 0.0360 - accuracy: 0.9998\n",
      "46/46 - 1s - loss: 1.6116 - accuracy: 0.6760 - 758ms/epoch - 16ms/step\n",
      "\n",
      "Test Accuracy: 67.60 %\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model using TensorFlow and Keras with Batch Normalization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(len(label_binarizer.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_encoded))\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay6fgGjjPH8d"
   },
   "source": [
    "**Key takeaways:**\n",
    "\n",
    "1.   CNN model with 32 filters and max pooling 2D showed 57.3% test accuracy\n",
    "2.   CNN model with data augmentation further improved the accuracy by 15-20%,  i.e., from a test data accuracy of 57.6 -> 67.6%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcGZR-Fp2R89"
   },
   "source": [
    "## **Model C: Transfer Learning Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dTonan9AuQ_",
    "outputId": "73d5b999-285c-4e24-dcdc-8e3f304c3fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 82s 338ms/step - loss: 3.7416 - accuracy: 0.4400\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 61s 334ms/step - loss: 0.5680 - accuracy: 0.8718\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 62s 335ms/step - loss: 0.0554 - accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0101 - accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0057 - accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0042 - accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0038 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0032 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 62s 334ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "46/46 - 5s - loss: 1.0918 - accuracy: 0.7595 - 5s/epoch - 118ms/step\n",
      "\n",
      "Test Accuracy: 75.95 %\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet50 model (with top layers)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Create a custom model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_encoded))\n",
    "\n",
    "# Train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(train_dataset.batch(32), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE97IVzH4bwh"
   },
   "source": [
    "### **Transfer Learning: Applying data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zZMhoq34gfU",
    "outputId": "f44ad0cd-6ff8-4eaa-ea80-db0f2b87f8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 0s 0us/step\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 82s 326ms/step - loss: 4.5971 - accuracy: 0.1731\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 64s 348ms/step - loss: 2.4255 - accuracy: 0.4129\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 64s 345ms/step - loss: 1.8082 - accuracy: 0.5510\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 64s 346ms/step - loss: 1.3889 - accuracy: 0.6423\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 64s 346ms/step - loss: 1.1050 - accuracy: 0.7091\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 64s 346ms/step - loss: 0.8888 - accuracy: 0.7627\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.6859 - accuracy: 0.8098\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 64s 348ms/step - loss: 0.5947 - accuracy: 0.8402\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 64s 348ms/step - loss: 0.4739 - accuracy: 0.8691\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.3963 - accuracy: 0.8826\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.3372 - accuracy: 0.8969\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.3014 - accuracy: 0.9159\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.2696 - accuracy: 0.9239\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 64s 348ms/step - loss: 0.2180 - accuracy: 0.9351\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.1851 - accuracy: 0.9428\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 64s 348ms/step - loss: 0.1866 - accuracy: 0.9463\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 64s 348ms/step - loss: 0.1547 - accuracy: 0.9562\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.1575 - accuracy: 0.9535\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.1383 - accuracy: 0.9592\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 64s 347ms/step - loss: 0.1184 - accuracy: 0.9648\n",
      "46/46 - 6s - loss: 1.0445 - accuracy: 0.8308 - 6s/epoch - 121ms/step\n",
      "\n",
      "Test Accuracy: 83.08 %\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert tensors to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_encoded))\n",
    "\n",
    "# Apply data augmentation and train the model using the tf.data.Dataset with batch size 32\n",
    "model.fit(datagen.flow(X_train, y_train_encoded, batch_size=32), epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print('\\n'f\"Test Accuracy: {test_accuracy*100:.2f}\", \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exusYz9NLrBT"
   },
   "source": [
    "**Key takeaways:**\n",
    "\n",
    "1.   Transfer learning ResNet pre-trained model showed an improvement in test data accuracy over CNN model by 15-20%\n",
    "2.   Transfer learning with data augmentation further improved the test data accuracy by 10%, i.e. from 75.8 -> 83.1%\n",
    "3.   Transfer learning showed the best test data accuracy ~ 85% close to our target ~ 90% \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
